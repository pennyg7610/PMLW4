---
title: "PML Project Report"
author: "Krystle Sawyer"
date: "2023-02-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

The goal of this project is to predict the manner in which 6 participants did their exercise (sitting, sitting down, standing, standing up, walking). This is the "classe" variable in the training set. Other variables may be utilized to predict with. This report describes how the model was built, how cross validation was used, what I think the expected out of sample error is, and why I made the choices I did. This prediction model will also be used to predict 20 different test cases. 


## Data 
The training data for this project is available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data is available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project comes from this source: http://groupware.les.inf.puc-rio.br/har. 

## Loading and cleaning data

Install packages, load and set seed
```{r cars}
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(dplyr)
library(gbm)
set.seed(250)
```


Load data
```{r}
training_data <-read.csv("pml-training.csv")
test_data <-read.csv("pml-testing.csv")

dim(training_data)
dim(test_data)
```

Clean data: Remove all columns with NAs, Remove near zero variance predictos, remove ID variables. 
```{r}
#remove columns with NA

training_data <- training_data %>% select_if(~ !any(is.na(.)))
test_data <- test_data %>% select_if(~ !any(is.na(.)))

dim(training_data)
dim(test_data)


#remove near zero variance predictors with caret package
nzv <- nearZeroVar(training_data)

training_data<- training_data[,-nzv]
test_data<- test_data[,-nzv]

#remove ID variables
training_data<-training_data[,-(1:5)]
test_data<-test_data[,-(1:5)]

```

## Partition of the Data
```{r}
in_train  <- createDataPartition(training_data$classe, p=0.75, list=FALSE)
train_set <- training_data[ in_train, ]
test_set  <- training_data[-in_train, ]

dim(train_set)

```


## Building of the Models

Decision Tree:
```{r}

decisiontree <- rpart(classe~., data = train_set, method = 'class')
rpart.plot(decisiontree)
```
Making a prediction:
```{r}
predict_decisiontree <-predict(decisiontree, newdata=test_set, type = 'class')

#counts number classified into classe
table_mat <- table(test_set$classe, predict_decisiontree)
table_mat

```
```{r}
conf_matrix<-confusionMatrix(predict_decisiontree, factor(test_set$classe))
conf_matrix
```
Accuracy is at 73%


Random Forest:
```{r}
train_set$classe <- factor(train_set$classe)

trControl <- trainControl(method = 'repeatedcv', number = 5)
model <- train(classe ~ ., data=train_set, method = "rf" )

model$finalModel



#Prediction
predRF <- predict(model, newdata= test_set)
RFconfusmatrix<- confusionMatrix(predRF, factor(test_set$classe))
RFconfusmatrix


ctrl_RF <- trainControl(method = "repeatedcv", number = 5, repeats = 2)
fit_RF  <- train(classe ~ ., data = train_set, method = "rf",  trControl = ctrl_RF, verbose = FALSE)



```




Generalized Boosted Model:

```{r}

ctrl_GBM <- trainControl(method = "repeatedcv", number = 5, repeats = 2)
fit_GBM  <- train(classe ~ ., data = train_set, method = "gbm",
                  trControl = ctrl_GBM, verbose = FALSE)
fit_GBM$finalModel

```




